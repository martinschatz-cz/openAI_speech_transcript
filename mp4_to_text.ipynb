{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We will need packages:\n",
        " * **moviepy** to conver mp4 to mp3\n",
        " * **openai** to use their `whisper-1` model for transcript\n",
        " * an `apenAI-API key`\n",
        "\n",
        "\n",
        "\n",
        " The transcript of this 11 minutes and 4 seconds long audio cost 0.07$.\n",
        "\n"
      ],
      "metadata": {
        "id": "MZ9a0nMFqWBF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pytYkkxMdU8",
        "outputId": "7dd20bd8-a5e7-4f90-94d3-3739c9aefb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: watermark in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Collecting openai\n",
            "  Downloading openai-1.3.0-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (6.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (67.7.2)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.17.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.19.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.9)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy watermark openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mp4 used is mine presentation about *Data Stewardship Course for Doctoral Candidates* (DOI: https://doi.org/10.48813/d2yw-gt72) published uder **CC-BY-4.0** from  [National EOSC Tripartite Event and Czech Open Science Day](https://repozitar.techlib.cz/search?f=conference_name&p=%22National%20EOSC%20Tripartite%20Event%20and%20Czech%20Open%20Science%20Day%22&ln=cs) event."
      ],
      "metadata": {
        "id": "MFt59Rt9pz--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repozitar.techlib.cz/record/1749/files/idr-1749_2.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohx8cExQosh-",
        "outputId": "f2b21416-3a11-4c40-b0a4-f92c27342f43"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-16 10:17:54--  https://repozitar.techlib.cz/record/1749/files/idr-1749_2.mp4\n",
            "Resolving repozitar.techlib.cz (repozitar.techlib.cz)... 195.113.241.45\n",
            "Connecting to repozitar.techlib.cz (repozitar.techlib.cz)|195.113.241.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48784034 (47M) [video/mp4]\n",
            "Saving to: ‘idr-1749_2.mp4’\n",
            "\n",
            "idr-1749_2.mp4      100%[===================>]  46.52M  1.37MB/s    in 36s     \n",
            "\n",
            "2023-11-16 10:18:31 (1.28 MB/s) - ‘idr-1749_2.mp4’ saved [48784034/48784034]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import *\n",
        "video = VideoFileClip(os.path.join(\"/content/idr-1749_2.mp4\"))\n",
        "video.audio.write_audiofile(os.path.join(\"/content/idr-1749_2_movie_sound.mp3\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6AoDqv0NF-v",
        "outputId": "3570f231-79c0-46d8-a543-e9da474b568e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/idr-1749_2_movie_sound.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing openai module into your openai environment\n",
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "rqY-KsuKM3Co"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key='sk-XXXX') #fill in your api key\n",
        "\n",
        "audio_file= open(\"/content/idr-1749_2_movie_sound.mp3\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  language=\"en\",\n",
        "  file=audio_file\n",
        ")"
      ],
      "metadata": {
        "id": "tuGcp74wNBaC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ68qdXBN0eZ",
        "outputId": "6347becb-6cb4-4007-e740-09f9cb17470f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transcription(text=\"Let's go next, Martin, please come here, another chemist in the panel and we are going to hear more about data stewardship course for doctoral candidates. The floor is yours. Thank you. Thank you for the introduction. Good afternoon. I would like to share with you our experience with piloting and also adapting the data stewardship course for the doctoral candidates. But I would like to start with where it actually came to existence and it was developed as a part of three courses under Doc Enhance project, which was from 2020 and 2022. It was a part of or there was 19 partners participating and all of it was led by the Arctic University of Norway. And since, as you can see, the project is already at the end, you can find already all of the training resources, courses, information on either the Doc Enhance platform, that's what's the QR code is there, so you can directly check it out, or you can find it also on the PhD hub. And all of the resources were made so they can be very easily adapted for the local needs and also shared. But let's get back to the data stewardship and what it is aimed for. It is aiming to introduce the PhD candidates to all the complexity of the research data management from finding the data, publishing, creating the DMPs, archiving data and much more. It was kind of implemented, improved during a set of steps, during two pilots. So there already existed some base course, base project at the beginning and during the two stages and during the feedbacks it was improved and kind of based on feedback changed. And you can find the final version at the Doc Enhance platform since there was actually quite significant changes. And how we do come in play in this? As a University of Chemistry and Technology, we were one of the two universities participating in the piloting of this course. For us, there was about 35 PhD candidates with about 8 teachers, but also we already edited the course and it already ran in 2023 with about 17 PhD candidates. One of the very good experiences for us was that some of the graduates, and I was one of them, started to also teach in the course and I hope that this will continue on because I mean that's one of the best experiences to continue with what you learn and to see how beneficial it can be for you and be motivated to share all of it for the future participants. Let's look at how the course is actually structured. There are three models. The first model is completely available online. It is kind of for a general introduction and finding all the relevant basic information and getting a feedback about whatever the participants know the same things. The second model is more practical. It's about the workshops and tasks and, of course, we were using the Data Stewardship Wizard as a part of it. And it's also a lot about team working because, I mean, you know as a scientist we don't usually work alone. We need to be able to share the information, knowledge, have the same terminology to understand each other. And the third model was about cooperation with businesses or public service entity. So the participants would be able to see how it actually works in practice in big companies and so on. Because sometimes like seeing how it is implemented somewhere it can like open your eyes how beneficial at the end it can all be. So the first model of the Data Stewardships includes 10 thematic issues. It is trying to walk through the participant through everything that is important. It is kind of based because all the rest can be very easily adapted to local needs. And there is a lot of videos and transcripts and suggestions so it doesn't mean that all of the participants will have to have the same time to go through. For someone it might take a week, for someone else it might be two afternoons since you might already have all the knowledge available. And for each, I believe, each of the parts there is a quiz so you can get a feedback on whatever you already have the knowledge needed. And the model one is ended with a kind of exam quiz with a certification where you need to have at least 80% or 24 for 30 ask questions. You have three tries for this so you can learn kind of from your mistakes. And it can automatically generate a certificate for you. As you can see it can be a bit customized. There's our logo and so on. And this is kind of an entrance thing to get to the rest of the models. The second model starts to be more practical with trainers where the participants work in a small group. It is about six very specific workshops. We implemented them into ours. I don't know if you can see the names but you can see some of the presenters that are here today that participated on the course. And kind of like one of our experiences that the first pilot was during the COVID time so it was online and the second one was in presence form. And there was a very significant difference in the speed of going through the workshops and so on because sitting next to the colleague being able to discuss what we were doing or asking him for help was very beneficial. So for example for doing the DMPs I believe we were a bit challenged to finishing up in the two hours. In the second run I believe all of the groups were able to do two or three of the DMPs for their topic and discuss a lot, ask a lot of very good questions and so on. So you can think about the model two as about applying the knowledge of what you learned before but also very important is the model three. You can think about this as about the seeing is believing. This part can be or should be actually very dependent on the local stakeholders and on what the university or the institution is doing because I mean each of our institutions can have different topic, each of the participants might be interested in seeing something different. For us it was about going to look at Orland petrol, how the full production looked like because they have very interested apps for looking like everything that is going on. So it is very easy to look in the past what was happening and for a lot of the participants it was very important and motivational to actually see how it can work because this was one of the motivation to do this in a way for their own lab or themselves like being able to find the results of experiments for last year and not having to like difficultly searching for it. So we had a lot of good feedback for the model three in general. And for the next steps what we wanted to do and what we want to do is that we want to implement the data stewardship in our regular curriculum for early career researchers. At the moment we are having the model one openly available for anyone on the learning platform. Also we want to share our experiments of conducting this course with other universities. We already started with the Faculty of Science of Charles University so I hope that there will be more of institutions and universities joining on or actually some of the communities because something I can see in the future that the communities can have a big role in this in implementing in future what we actually will plan or create in Czech Republic. So the course will be up to date and let's say others can use it and join it. And of course in this case getting feedback and for implementing what we learn is very important as we did here yesterday and today we are like moving forward. There will be a lot of changes and it is important to learn about it. And of course there should be the whole course available also here at the NTK. So it was brief but I hope it was beneficial for you. So thank you for your attention. Perfect. Thank you very much Martin. Thank you very much. That was a leap to education and we will continue with that.\")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from watermark import watermark\n",
        "watermark(iversions=True, globals_=globals())\n",
        "print(watermark())\n",
        "print(watermark(packages=\"watermark,openai,moviepy\"))"
      ],
      "metadata": {
        "id": "EiequXkeOXi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ec91f8-5dfb-4810-acf1-9bba1cfbaee1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last updated: 2023-11-16T10:21:46.340344+00:00\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 5.15.120+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "watermark: 2.4.3\n",
            "openai   : 1.3.0\n",
            "moviepy  : 1.0.3\n",
            "\n"
          ]
        }
      ]
    }
  ]
}