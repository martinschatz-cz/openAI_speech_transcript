{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22145da9-58b2-457b-b3fd-f3eeb4bdaea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nvidia-cublas-cu11 nvidia-cudnn-cu11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ad47a8-cd12-4e57-9df1-f1f7905b43e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\.conda\\envs\\transcribe\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "from watermark import watermark\n",
    "\n",
    "# %env OMP_NUM_THREADS 512\n",
    "\n",
    "model_size = \"large-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f705c45-1cf2-4ea5-9cbc-7983fdcf4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on GPU with FP16\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91fe7e58-8198-40a7-b77f-47dabd324378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 0.628612\n",
      "[0.00s -> 11.04s]  Let's go next, Martin, please come here, another chemist in the panel and we are going to hear\n",
      "[11.04s -> 13.98s]  more about data stewardship course for doctoral candidates.\n",
      "[13.98s -> 15.96s]  The floor is yours.\n",
      "[15.96s -> 16.96s]  Thank you.\n",
      "[16.96s -> 18.92s]  Thank you for the introduction.\n",
      "[18.92s -> 20.76s]  Good afternoon.\n",
      "[20.76s -> 27.60s]  I would like to share with you our experience with piloting and also adapting the data\n",
      "[27.60s -> 32.08s]  stewardship course for the doctoral candidates.\n",
      "[32.08s -> 39.48s]  But I would like to start with where it actually came to existence and it was developed as\n",
      "[39.48s -> 47.68s]  a part of three courses under Doc Enhance project, which was from 2020 and 2022.\n",
      "[47.68s -> 56.52s]  It was a part of or there was 19 partners participating and all of it was led by the\n",
      "[56.52s -> 59.80s]  Arctic University of Norway.\n",
      "[59.80s -> 65.64s]  And since, as you can see, the project is already at the end, you can find already all\n",
      "[65.64s -> 74.24s]  of the training resources, courses, information on either the Doc Enhance platform, that's\n",
      "[74.24s -> 78.00s]  what's the QR code is there, so you can directly check it out.\n",
      "[78.00s -> 82.72s]  Or you can find it also on the PhD hub.\n",
      "[82.72s -> 90.08s]  And all of the resources were made so they can be very easily adapted for the local needs\n",
      "[90.08s -> 93.96s]  and also shared.\n",
      "[93.96s -> 100.00s]  But let's get back to the data stewardship and what it is aimed for.\n",
      "[100.00s -> 107.88s]  It is aiming to introduce the PhD candidates to all the complexity of the research data\n",
      "[108.04s -> 119.04s]  management, from finding the data, publishing, creating the DMPs, archiving data and much more.\n",
      "[119.04s -> 126.92s]  It was kind of implemented, improved during a set of steps, during two pilots.\n",
      "[126.92s -> 133.60s]  So there already existed some base course, base project at the beginning and during the\n",
      "[133.72s -> 145.48s]  two stages and during the feedbacks it was improved and kind of based on feedback changed.\n",
      "[145.48s -> 150.56s]  And you can find the final version at the Doc Enhance platform since there was actually\n",
      "[150.56s -> 153.36s]  quite significant changes.\n",
      "[153.36s -> 157.64s]  And how we do come in play in this?\n",
      "[157.68s -> 164.56s]  As a University of Chemistry and Technology, we were one of the two universities participating\n",
      "[164.56s -> 168.36s]  in the piloting of this course.\n",
      "[168.36s -> 177.24s]  For us, there was about 35 PhD candidates with about 8 teachers, but also we already\n",
      "[177.24s -> 184.76s]  edited the course and it already ran in 2023 with about 17 PhD candidates.\n",
      "[184.76s -> 190.84s]  One of the very good experiences for us was that some of the graduates, and I was one\n",
      "[190.84s -> 198.36s]  of them, started to also teach in the course and I hope that this will continue on because\n",
      "[198.36s -> 205.68s]  I mean that's one of the best experiences to continue with what you learn and to see\n",
      "[205.68s -> 214.64s]  how beneficial it can be for you and be motivated to share all of it for the future participants.\n",
      "[214.92s -> 219.84s]  Let's look at how the course is actually structured.\n",
      "[219.84s -> 221.60s]  There are three models.\n",
      "[221.60s -> 226.76s]  The first model is completely available online.\n",
      "[226.76s -> 234.60s]  It is kind of for a general introduction and finding all the relevant basic information\n",
      "[234.60s -> 242.72s]  and getting a feedback about whatever the participants know the same things.\n",
      "[242.72s -> 245.00s]  The second model is more practical.\n",
      "[245.00s -> 249.64s]  It's about the workshops and tasks and of course we were using the Data Stavership\n",
      "[249.64s -> 252.68s]  Wizard as a part of it.\n",
      "[252.68s -> 258.08s]  And it's also a lot about team working because, I mean, you know as a scientist we don't usually\n",
      "[258.08s -> 259.08s]  work alone.\n",
      "[259.08s -> 265.04s]  We need to be able to share the information, knowledge, have the same terminology to understand\n",
      "[265.04s -> 266.32s]  each other.\n",
      "[266.32s -> 274.20s]  And the third model was about cooperation with businesses or public service entity.\n",
      "[274.20s -> 280.20s]  So the participants would be able to see how it actually works in practice in big companies\n",
      "[280.20s -> 281.60s]  and so on.\n",
      "[281.60s -> 289.60s]  Because sometimes like seeing how it is implemented somewhere it can like open your eyes how beneficial\n",
      "[289.60s -> 293.88s]  at the end it can all be.\n",
      "[293.88s -> 300.04s]  So the first model of the Data Staverships includes 10 thematic issues.\n",
      "[300.04s -> 307.32s]  It is trying to walk through the participant through everything that is important.\n",
      "[307.32s -> 314.16s]  It is kind of based because all the rest can be very easily adapted to local needs.\n",
      "[314.16s -> 320.00s]  And there is a lot of videos and transcripts and suggestions so it doesn't mean that all\n",
      "[320.08s -> 324.92s]  of the participants will have to have the same time to go through.\n",
      "[324.92s -> 330.84s]  For someone it might take a week, for someone else it might be two afternoons since you\n",
      "[330.84s -> 335.00s]  might already have all the knowledge available.\n",
      "[335.00s -> 341.48s]  And for each, I believe, each of the parts there is a quiz so you can get a feedback\n",
      "[341.48s -> 345.32s]  on whatever you already have the knowledge needed.\n",
      "[345.32s -> 353.28s]  And the model one is ended with a kind of exam quiz with a certification where you\n",
      "[353.28s -> 360.00s]  need to have at least 80% or 24 for 30 ask questions.\n",
      "[360.00s -> 366.00s]  You have three tries for this so you can learn kind of from your mistakes and it can automatically\n",
      "[366.00s -> 369.08s]  generate a certificate for you.\n",
      "[369.08s -> 373.64s]  As you can see it can be a bit customized, there's our logo and so on.\n",
      "[373.64s -> 380.56s]  And this is kind of an entrance thing to get to the rest of the models.\n",
      "[380.56s -> 387.64s]  The second model starts to be more practical with trainers where the participants work\n",
      "[387.64s -> 390.00s]  in a small group.\n",
      "[390.00s -> 393.68s]  It is about six very specific workshops.\n",
      "[393.68s -> 396.56s]  We implemented them in two hours.\n",
      "[396.56s -> 401.76s]  I don't know if you can see the names but you can see some of the presenters that are\n",
      "[401.88s -> 405.84s]  here today that participated on the course.\n",
      "[405.84s -> 414.12s]  And kind of like one of our experiences that the first pilot was during the COVID time\n",
      "[414.12s -> 421.56s]  so it was online and the second one was in presence form and there was a very significant\n",
      "[421.56s -> 428.44s]  differences in the speed of going through the workshops and so on because sitting next\n",
      "[428.48s -> 434.96s]  to the colleague being able to discuss what we were doing or asking him for help was very\n",
      "[434.96s -> 436.08s]  beneficial.\n",
      "[436.08s -> 443.64s]  So for example for doing the DMPs I believe we were a bit challenged to finishing up in\n",
      "[443.64s -> 444.64s]  the two hours.\n",
      "[444.64s -> 452.52s]  In the second run I believe all of the groups were able to do two or three of the DMPs for\n",
      "[452.60s -> 459.48s]  their topic and discuss a lot, ask a lot of very good questions and so on.\n",
      "[459.48s -> 466.52s]  So you can think about the model two as about applying the knowledge of what you learned\n",
      "[466.52s -> 472.80s]  before but also very important is the model three.\n",
      "[472.80s -> 478.24s]  You can think about this as about the seeing is believing.\n",
      "[478.24s -> 484.68s]  This part can be or should be actually very dependent on the local stakeholders and on\n",
      "[484.68s -> 491.20s]  what the university or the institution is doing because I mean each of our institutions\n",
      "[491.20s -> 498.24s]  can have different topic, each of the participants might be interested in seeing something different.\n",
      "[498.24s -> 506.36s]  For us it was about going to look at Orland petrol, how the full production looked like\n",
      "[506.56s -> 512.40s]  because they have very interested apps for looking like everything that is going on.\n",
      "[512.40s -> 520.16s]  So it is very easy to look in the past what was happening and for a lot of the participants\n",
      "[520.16s -> 527.56s]  it was very important and motivational to actually see how it can work because this\n",
      "[527.56s -> 535.08s]  was one of the motivation to do this in a way for their own lab or themselves like being\n",
      "[535.08s -> 543.16s]  able to find the results of experiments for last year and not having to like difficultly\n",
      "[543.16s -> 544.68s]  searching for it.\n",
      "[544.68s -> 551.68s]  So we had a lot of good feedback for the model three in general.\n",
      "[551.68s -> 557.96s]  And for the next steps what we wanted to do and what we want to do is that we want to\n",
      "[557.96s -> 565.04s]  implement the data stewardship in our regular curriculum for early career researchers.\n",
      "[565.04s -> 570.24s]  At the moment we are having the model one openly available for anyone on the learning\n",
      "[570.24s -> 572.12s]  platform.\n",
      "[572.12s -> 577.36s]  Also we want to share our experiments of conducting this course with other universities.\n",
      "[577.36s -> 583.60s]  We already started with the Faculty of Science of Charles University so I hope that there\n",
      "[583.60s -> 589.80s]  will be more of institutions and universities joining on or actually some of the communities\n",
      "[589.80s -> 597.44s]  because something I can see in the future that the communities can have a big role in\n",
      "[597.44s -> 605.28s]  this in implementing in future what we actually will plan or create in Czech Republic so the\n",
      "[605.28s -> 612.88s]  course will be up to date and let's say others can use it and join it.\n",
      "[612.88s -> 621.84s]  And of course in this case getting feedback and for implementing what we learn is very\n",
      "[621.84s -> 627.44s]  important as we did here yesterday and today we are like moving forward.\n",
      "[627.44s -> 631.96s]  There will be a lot of changes and it is important to learn about it.\n",
      "[631.96s -> 642.16s]  And of course there should be the whole course available also here at the NTK.\n",
      "[642.16s -> 653.04s]  So it was brief but I hope it was beneficial for you so thank you for your attention.\n",
      "[653.04s -> 654.04s]  Thank you very much Martin.\n",
      "[654.04s -> 655.04s]  Thank you very much.\n",
      "[655.04s -> 658.72s]  That was a leap to education and we will continue with that.\n",
      "CPU times: total: 41min 32s\n",
      "Wall time: 36min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "segments, info = model.transcribe(\"idr-1749_2_movie_sound.mp3\", beam_size=5)\n",
    "# segments, info = model.transcribe(\"output.mp3\", beam_size=5)\n",
    "\n",
    "print(\n",
    "    \"Detected language '%s' with probability %f\"\n",
    "    % (info.language, info.language_probability)\n",
    ")\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2bf8ca4-db89-42c5-b008-54d63c3182ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-11-17T08:51:06.979235+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.18\n",
      "IPython version      : 8.17.2\n",
      "\n",
      "Compiler    : MSC v.1929 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "CPU cores   : 20\n",
      "Architecture: 64bit\n",
      "\n",
      "watermark     : 2.4.3\n",
      "faster_whisper: 0.9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watermark(iversions=True, globals_=globals())\n",
    "print(watermark())\n",
    "print(watermark(packages=\"watermark,faster_whisper\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef6335-7bef-4e7f-a2f6-9b1a5d32d2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
